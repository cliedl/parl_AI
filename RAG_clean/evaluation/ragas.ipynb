{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "DATABASE_DIR_MANIFESTOS = \"../../data/manifestos/chroma/manifestoberta\"\n",
    "DATABASE_DIR_DEBATES = \"../../data/manifestos/chroma/manifestoberta\"\n",
    "TEST_DATA_DIR = \"../../data/questions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from database.vector_database import VectorDatabase\n",
    "from models.embedding import ManifestoBertaEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create simple chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christianliedl/anaconda3/envs/bundestag/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at manifesto-project/manifestoberta-xlm-roberta-56policy-topics-sentence-2023-1-1 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reloaded database\n"
     ]
    }
   ],
   "source": [
    "from models.generation import generate_chain_with_balanced_retrieval\n",
    "\n",
    "embedding_model = ManifestoBertaEmbeddings()\n",
    "\n",
    "db_manifestos = VectorDatabase(\n",
    "    data_path=\"../data/manifestos\",\n",
    "    embedding_model=embedding_model,\n",
    "    database_directory=DATABASE_DIR_MANIFESTOS,\n",
    "    source_type=\"manifestos\",\n",
    ")\n",
    "\n",
    "chain = generate_chain_with_balanced_retrieval(\n",
    "    [db_manifestos]\n",
    ")  # add more databases here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cdu_summary': 'Die CDU/CSU setzt sich für eine starke Sozialstaatlichkeit ein und betont die Bedeutung sozialer Sicherungssysteme. Sie lehnt eine Einflussnahme der EU auf den Betrieb und die Finanzierung von Krankenhäusern in Deutschland ab und spricht sich gegen eine weitere Privatisierung im Gesundheitswesen aus. Zudem betont sie die Notwendigkeit, den Zugang zu Arzneimitteln für seltene Erkrankungen sicherzustellen.',\n",
       " 'spd_summary': 'Die SPD setzt sich für die Überwindung von Wohnungslosigkeit bis 2030 ein und unterstützt die Europäische Plattform zur Bekämpfung von Wohnungslosigkeit. Sie strebt einen sicheren Zugang zu Gesundheitsversorgung für alle Bürger in Europa an und fordert eine weitere Stärkung der Pflege durch staatliche Investitionen und verbindliche europäische Regelungen.',\n",
       " 'gruene_summary': 'Bündnis 90/Die Grünen legen den Fokus auf Prävention und Gesundheitsförderung in ihrer Gesundheitspolitik. Sie setzen sich für die Stärkung der Kinderrechte ein und betonen die Bedeutung von gesicherten Wohnverhältnissen für alle Menschen, insbesondere in Bezug auf bezahlbaren Wohnraum und soziale Ungleichheit.',\n",
       " 'linke_summary': 'Die Linke kritisiert die Auswirkungen der neoliberalen Grundlagen in der EU, die zu Ungleichheit und Privatisierung öffentlicher Dienstleistungen geführt haben. Sie setzt sich für eine starke Linke im Europaparlament ein, um gegen Missstände wie Armut, marode Gesundheitssysteme und explodierende Mieten vorzugehen.',\n",
       " 'fdp_summary': 'Die FDP strebt danach, Europas Energie für mehr Freiheit und Wohlstand zu entfesseln. Sie setzt sich für eine bessere Kooperation zwischen der EU und der Weltgesundheitsorganisation ein und fordert die Schaffung eines gemeinsamen Europäischen Gesundheitsdatenraums. Zudem betont sie die Notwendigkeit, die Bürokratie im Gesundheitsbereich zu reduzieren und den Zugang zu Arzneimitteln sicherzustellen.',\n",
       " 'afd_summary': 'Die AfD kritisiert die Ungleichverteilung der Vermögen in Deutschland und setzt sich gegen eine weitere Privatisierung im Gesundheitswesen ein. Sie lehnt eine Einflussnahme der EU auf den Betrieb und die Finanzierung von Krankenhäusern in Deutschland ab und fordert die Rehabilitierung von Bürgern, die rechtliche Nachteile aufgrund ihrer kritischen Haltung zur staatlichen Impf- und Corona-Politik erlitten haben.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Was sind die Position der Partein zur Rentenpolitik?\"\n",
    "response = chain.invoke(question)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test_simple = pd.read_csv(os.path.join(\n",
    "    TEST_DATA_DIR, \"simple_questions.csv\"))\n",
    "\n",
    "df_test_complex = pd.read_csv(os.path.join(\n",
    "    TEST_DATA_DIR, \"complex_questions.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Eval chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_relevancy,\n",
    "    context_recall,\n",
    ")\n",
    "from ragas.langchain import RagasEvaluatorChain\n",
    "\n",
    "# create eval chains\n",
    "eval_chains = {m.name: RagasEvaluatorChain(\n",
    "    metric=m) for m in [context_relevancy]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run eval chain for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "Was denken die Parteien darüber, mehr Geld für die Armee auszugeben, um Europa sicher zu halten?\n",
      "context_relevancy_score: 0.0\n",
      "context_relevancy_score: 0.05128205128205128\n",
      "context_relevancy_score: 0.11458333333333333\n",
      "context_relevancy_score: 0.03278688524590164\n",
      "context_relevancy_score: 0.0\n",
      "context_relevancy_score: 0.0\n",
      "_____________________________________\n",
      "Was sagen die Parteien, wie wir Transgender-Menschen helfen und dafür sorgen können, dass alle fair behandelt werden?\n",
      "context_relevancy_score: 0.11494252873563218\n",
      "context_relevancy_score: 0.10256410256410256\n",
      "context_relevancy_score: 0.0\n",
      "context_relevancy_score: 0.0\n",
      "context_relevancy_score: 0.12903225806451613\n",
      "context_relevancy_score: 0.2222222222222222\n",
      "_____________________________________\n",
      "Sollen wir in Europa mehr für den Schutz unserer Umwelt tun?\n",
      "context_relevancy_score: 0.06796116504854369\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[57], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, eval_chain \u001b[38;5;129;01min\u001b[39;00m eval_chains\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     23\u001b[0m     score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_score\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 24\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43meval_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m[score_name]\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscores\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     metrics[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparty\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(scores)\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/langchain/chains/base.py:378\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    371\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    376\u001b[0m }\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/langchain/chains/base.py:163\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    162\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    164\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/langchain/chains/base.py:153\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    152\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 153\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    159\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/ragas/langchain/evalchain.py:70\u001b[0m, in \u001b[0;36mRagasEvaluatorChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m     68\u001b[0m question \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     69\u001b[0m answer \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 70\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43manswer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontexts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mground_truths\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mground_truths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_score\u001b[39m\u001b[38;5;124m\"\u001b[39m: score}\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/ragas/metrics/base.py:101\u001b[0m, in \u001b[0;36mMetric.score_single\u001b[0;34m(self, ds_row, callbacks)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# TODO: validation check if they are string\u001b[39;00m\n\u001b[1;32m    100\u001b[0m ds \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict({k: [v] \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m ds_row\u001b[38;5;241m.\u001b[39mitems()})\n\u001b[0;32m--> 101\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback_group_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/ragas/metrics/_context_relevancy.py:85\u001b[0m, in \u001b[0;36mContextRelevancy._score_batch\u001b[0;34m(self, dataset, callbacks, callback_group_name)\u001b[0m\n\u001b[1;32m     82\u001b[0m     prompts\u001b[38;5;241m.\u001b[39mappend(ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([human_prompt]))\n\u001b[1;32m     84\u001b[0m responses: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 85\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m responses \u001b[38;5;241m=\u001b[39m [[i\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m r] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mgenerations]\n\u001b[1;32m     92\u001b[0m scores \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/ragas/llms/openai.py:153\u001b[0m, in \u001b[0;36mOpenAIBase.generate\u001b[0;34m(self, prompts, n, temperature, callbacks)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    148\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[ChatPromptTemplate],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m     callbacks: t\u001b[38;5;241m.\u001b[39mOptional[Callbacks] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mAny:  \u001b[38;5;66;03m# TODO: LLMResult\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     llm_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_async_tasks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m     generations \u001b[38;5;241m=\u001b[39m [r\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m llm_results]\n\u001b[1;32m    158\u001b[0m     llm_output \u001b[38;5;241m=\u001b[39m _compute_token_usage_langchain(llm_results)\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/ragas/async_utils.py:42\u001b[0m, in \u001b[0;36mrun_async_tasks\u001b[0;34m(tasks, show_progress, progress_bar_desc)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks_to_execute)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     outputs: List[Any] \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_gather\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# run the operation w/o tqdm on hitting a fatal\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# may occur in some environments where tqdm.asyncio\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# is not supported\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFatal error occurred while running async tasks.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/nest_asyncio.py:92\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/site-packages/nest_asyncio.py:115\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m     heappop(scheduled)\n\u001b[1;32m    110\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[1;32m    113\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[1;32m    118\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[0;32m~/anaconda3/envs/bundestag/lib/python3.11/selectors.py:566\u001b[0m, in \u001b[0;36mKqueueSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 566\u001b[0m     kev_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mcontrol(\u001b[38;5;28;01mNone\u001b[39;00m, max_ev, timeout)\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = {}\n",
    "for party in sources:\n",
    "    for name, _ in eval_chains.items():\n",
    "        metrics.update({f\"{name}_score_{party}\": []})\n",
    "\n",
    "sources = [\"gruene\", \"spd\", \"cdu\", \"afd\", \"fdp\", \"linke\"]\n",
    "\n",
    "for question in df_test_simple[\"EINFACHE FRAGEN\"]:\n",
    "    print(\"_____________________________________\")\n",
    "    print(question)\n",
    "    # Rename keys to be compatible with eval_chain\n",
    "    output = {}\n",
    "    output[\"query\"] = question\n",
    "\n",
    "    for party in sources:\n",
    "        output[\"source_documents\"] = db_manifestos.database.similarity_search(\n",
    "            query=question, k=5, filter={\"party\": party}\n",
    "        )\n",
    "        output[\"result\"] = \"\"\n",
    "\n",
    "        # Evaluate one metric at a time\n",
    "        for name, eval_chain in eval_chains.items():\n",
    "            score_name = f\"{name}_score\"\n",
    "            scores = eval_chain(output)[score_name]\n",
    "            print(f\"{score_name}_{party}: {scores}\")\n",
    "            metrics[f\"{score_name}_{party}\"].append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____________________________________\n",
      "Was denken die Parteien darüber, mehr Geld für die Armee auszugeben, um Europa sicher zu halten?\n",
      "ChatCompletionMessage(content='1: 1\\n2: 1\\n3: 0\\n4: 0\\n5: 1', role='assistant', function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='1, 1, 0, 1, 0', role='assistant', function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='1, 1, 1, 0, 1', role='assistant', function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='1, 0, 1, 1, 0', role='assistant', function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='1, 2, 3, 4, 5', role='assistant', function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='1, 1, 1, 1, 0', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "for question in df_test_simple[\"EINFACHE FRAGEN\"].iloc[:1]:\n",
    "\n",
    "    sources = [\"gruene\", \"spd\", \"cdu\", \"afd\", \"fdp\", \"linke\"]\n",
    "\n",
    "    print(\"_____________________________________\")\n",
    "    print(question)\n",
    "    # Rename keys to be compatible with eval_chain\n",
    "    output = {}\n",
    "    output[\"query\"] = question\n",
    "\n",
    "    for party in sources:\n",
    "        output[\"source_documents\"] = db_manifestos.database.similarity_search(\n",
    "            query=question, k=5, filter={\"party\": party}\n",
    "        )\n",
    "\n",
    "        instruction = \"\"\"Du hilfst mir bei der Evaluation eines RAG systems. Bewerte, ob die folgenden Dokumente relevant sind für die Frage. Antworte mit einer List, in der für jedes Dokument entweder 0 (nicht relevant) oder 1 (relevant) ausgegeben wird.\n",
    "        Beispiel: [0, 1, 1, 1, 0]\"\"\"\n",
    "\n",
    "        context = \"\"\n",
    "        for i, doc in enumerate(output[\"source_documents\"]):\n",
    "            context += f\"\"\"Dokument {i+1}: {doc.page_content}\\n\\n\\n\n",
    "            \"\"\"\n",
    "        prompt = f\"{instruction}\\n\\n\\nHier sind die Dokumente:\\n{context}\\n\\n\\nHier ist die Frage:{question}\"\n",
    "\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            temperature=0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='1, 1, 1, 1, 1', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(metrics)\n",
    "df_metrics.loc[:, \"question\"] = df_test_simple[\"EINFACHE FRAGEN\"]\n",
    "df_metrics.to_csv(\"metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'faithfulness_mean': 0.6958333333333333,\n",
       " 'answer_relevancy_mean': 0.8132587018852587,\n",
       " 'context_relevancy_mean': 0.08362864874686092}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics = pd.read_csv(\"metrics.csv\")\n",
    "\n",
    "{key + \"_mean\": np.mean(df_metrics[key]) for key in metrics.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bundestag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
