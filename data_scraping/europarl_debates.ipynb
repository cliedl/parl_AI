{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# xml libraries\n",
    "import xml.etree.ElementTree as ET\n",
    "import elementpath as ep\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mep(term):\n",
    "    # gets information about all members of parlament\n",
    "    base_url = \"https://data.europarl.europa.eu/api/v1/\"\n",
    "    format = \"application%2Fld%2Bjson\"\n",
    "    query = f\"meps?parliamentary-term={term}&format={format}\"\n",
    "\n",
    "    url = base_url + query\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_documents(work_type, offset=0, limit=100, verbose=False):\n",
    "    base_url = \"https://data.europarl.europa.eu/api/v1/\"\n",
    "\n",
    "    format = \"application%2Fld%2Bjson\"  # response content is json format\n",
    "\n",
    "    query = f\"documents?work-type={work_type}&offset={offset}&limit={limit}&format={format}\"\n",
    "\n",
    "    url = base_url+query\n",
    "\n",
    "    if verbose:\n",
    "        print(url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_document_by_id(id, language=\"de\", verbose=False):\n",
    "    base_url = \"https://data.europarl.europa.eu/api/v1/documents/\"\n",
    "\n",
    "    format = \"application%2Fld%2Bjson\"  # response content is json format\n",
    "\n",
    "    query = f\"{id}?format={format}&language={language}\"\n",
    "\n",
    "    url = base_url+query\n",
    "    if verbose:\n",
    "        print(url)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None, url\n",
    "\n",
    "\n",
    "def get_file_location(document):\n",
    "\n",
    "    # If document is \"ComplexWork\", find the current version and load it\n",
    "    if document[\"type\"] == \"ComplexWork\":\n",
    "        current_version_id = document[\"hasCurrentVersion\"].split(\"/\")[-1]\n",
    "        document = get_document_by_id(current_version_id).json()[\"data\"][0]\n",
    "\n",
    "    # Get all availbale files, check format and save only xml file\n",
    "    files = document[\"is_realized_by\"][0][\"is_embodied_by\"]\n",
    "    for file in files:\n",
    "        format = file[\"format\"].split(\"/\")[-1]\n",
    "        if format == \"XML\":\n",
    "            file_location = file[\"is_exemplified_by\"]\n",
    "            break\n",
    "\n",
    "    return file_location\n",
    "\n",
    "\n",
    "def get_xml_doc(file_location, verbose=False):\n",
    "\n",
    "    base_url = \"https://data.europarl.europa.eu/\"\n",
    "    url = base_url+file_location\n",
    "\n",
    "    if verbose:\n",
    "        print(url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        xml_doc = ET.fromstring(response.content)\n",
    "        return xml_doc\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_speeches_from_xml(xml_doc):\n",
    "    # Extract speaches from plenary session document\n",
    "\n",
    "    text_list = []\n",
    "    mep_ip_list = []\n",
    "    date_list = []\n",
    "    topic_list = []\n",
    "\n",
    "    date = xml_doc.find(\"HEAD\").find(\"META\").text\n",
    "    chapters = xml_doc.find(\"DEBATS\").findall(\"CHAPTER\")\n",
    "\n",
    "    for chapter in chapters:\n",
    "        # Find topic of chapter in German\n",
    "        chapter_topic = chapter.find(\"TL-CHAP[@VL='DE']\").text\n",
    "\n",
    "        interventions = chapter.findall(\"INTERVENTION\")\n",
    "        for intervention in interventions:\n",
    "            speaker = intervention.find(\"ORATEUR\")\n",
    "            # member of parlament id\n",
    "            mep_ip = speaker.attrib[\"MEPID\"]\n",
    "            # if speach in German\n",
    "            if speaker.attrib[\"LG\"] == \"DE\":\n",
    "                # find all paragraphs and concatenate to single string\n",
    "                paragraphs = intervention.findall(\"PARA\")\n",
    "                text = \"\"\n",
    "                for paragraph in paragraphs:\n",
    "                    text += \" \".join([text for text in paragraph.itertext()])\n",
    "\n",
    "                # Append to array\n",
    "                text_list.append(text)\n",
    "                mep_ip_list.append(mep_ip)\n",
    "                date_list.append(date)\n",
    "                topic_list.append(chapter_topic)\n",
    "\n",
    "    df_speeches = pd.DataFrame({\"date\": date, \"topic\": topic_list,\n",
    "                                \"text\": text_list, \"mep_id\": mep_ip_list})\n",
    "    return df_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all documents of type\n",
    "type = \"PLENARY_CRE_EP\"\n",
    "\n",
    "document_list = []\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        doc_list = get_documents(\n",
    "            type, offset=i*100, limit=100).json()[\"data\"]\n",
    "        if len(doc_list) == 0:\n",
    "            break\n",
    "        else:\n",
    "            document_list.extend(doc_list)\n",
    "    except:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "df_documents = pd.DataFrame(\n",
    "    {\"identifier\": [doc[\"identifier\"] for doc in document_list]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4548b142b88e4b7a95fb90a1d1bf1ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, id: CRE-6-2008-09-22, Error:'is_realized_by'\n",
      "Step 1, id: CRE-6-2008-09-22-FNL, Error:'is_realized_by'\n",
      "Step 658, id: CRE-8-2018-04-19-PRV, Error:'NoneType' object has no attribute 'text'\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "failed_documents = []\n",
    "for i, id in tqdm(enumerate(df_documents.identifier), total=len(df_documents)):\n",
    "\n",
    "    try:\n",
    "        # Get document\n",
    "        document = get_document_by_id(id).json()[\"data\"][0]\n",
    "\n",
    "        # Extract xml file location\n",
    "        file_location = get_file_location(document)\n",
    "\n",
    "        # Download xml file\n",
    "        xml_doc = get_xml_doc(file_location)\n",
    "\n",
    "        # Extract speeches from xml file\n",
    "        df_ = parse_speeches_from_xml(xml_doc)\n",
    "\n",
    "        # Append to pd.DataFrame\n",
    "        df = pd.concat([df, df_])\n",
    "    except Exception as error:\n",
    "        print(f\"Step {i}, id: {id}, Error:{error}\")\n",
    "        failed_documents.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 failed documents out of a total of 1601 !!!\n",
      "Find out what is happening!!!\n",
      "[0, 1, 658]\n"
     ]
    }
   ],
   "source": [
    "# TODO!!!\n",
    "print(f\"{len(failed_documents)} failed documents out of a total of {len(document_list)} !!!\")\n",
    "print(\"Find out what is happening!!!\")\n",
    "\n",
    "print(failed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and reset index\n",
    "df = df.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Convert date to datetime format\n",
    "df[\"date\"] = pd.to_datetime(df.date, format=\"%d-%m-%Y\")\n",
    "\n",
    "# Change mep_ip type to int\n",
    "df[\"mep_id\"] = df[\"mep_id\"].astype(\"Int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mep = pd.DataFrame()\n",
    "for term in range(10):\n",
    "    mep = get_mep(term=term).json()[\"data\"]\n",
    "    df_mep = pd.concat([df_mep, pd.DataFrame(mep)])\n",
    "\n",
    "df_mep = df_mep.set_index(\"identifier\")\n",
    "df_mep.index = df_mep.index.astype(\"Int32\")\n",
    "df_mep = df_mep.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"givenName\"] = df[\"mep_id\"].apply(\n",
    "    lambda x: df_mep.loc[x].givenName if x in df_mep.index else None)\n",
    "df[\"familyName\"] = df[\"mep_id\"].apply(\n",
    "    lambda x: df_mep.loc[x].familyName if x in df_mep.index else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "df.to_csv(\"../data/debates/europarl_speaches.csv\")\n",
    "df_mep.to_csv(\"../data/debates/europarl_members.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bundestag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
