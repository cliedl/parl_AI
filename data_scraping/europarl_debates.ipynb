{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# xml libraries\n",
    "import xml.etree.ElementTree as ET\n",
    "import elementpath as ep\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mep_party():\n",
    "    url = \"https://www.europarl.europa.eu/meps/en/full-list/xml\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        xml_doc = ET.fromstring(response.content)\n",
    "        return xml_doc\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_mep(term):\n",
    "    # gets information about all members of parlament\n",
    "    base_url = \"https://data.europarl.europa.eu/api/v2/\"\n",
    "    format = \"application%2Fld%2Bjson\"\n",
    "    query = f\"meps?parliamentary-term={term}&format={format}\"\n",
    "\n",
    "    url = base_url + query\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_documents(work_type, offset=0, limit=100, verbose=False):\n",
    "    base_url = \"https://data.europarl.europa.eu/api/v2/\"\n",
    "\n",
    "    format = \"application%2Fld%2Bjson\"  # response content is json format\n",
    "\n",
    "    query = (\n",
    "        f\"documents?work-type={work_type}&offset={offset}&limit={limit}&format={format}\"\n",
    "    )\n",
    "\n",
    "    url = base_url + query\n",
    "\n",
    "    if verbose:\n",
    "        print(url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_document_by_id(id, language=\"de\", verbose=False):\n",
    "    base_url = \"https://data.europarl.europa.eu/api/v2/documents/\"\n",
    "\n",
    "    format = \"application%2Fld%2Bjson\"  # response content is json format\n",
    "\n",
    "    query = f\"{id}?format={format}&language={language}\"\n",
    "\n",
    "    url = base_url + query\n",
    "    if verbose:\n",
    "        print(url)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None, url\n",
    "\n",
    "\n",
    "def get_file_location(document):\n",
    "\n",
    "    # If document is \"ComplexWork\", find the current version and load it\n",
    "    if document[\"type\"] == \"ComplexWork\":\n",
    "        current_version_id = document[\"hasCurrentVersion\"].split(\"/\")[-1]\n",
    "        document = get_document_by_id(current_version_id).json()[\"data\"][0]\n",
    "\n",
    "    # Get all availbale files, check format and save only xml file\n",
    "    files = document[\"is_realized_by\"][0][\"is_embodied_by\"]\n",
    "    for file in files:\n",
    "        format = file[\"format\"].split(\"/\")[-1]\n",
    "        if format == \"XML\":\n",
    "            file_location = file[\"is_exemplified_by\"]\n",
    "            break\n",
    "\n",
    "    return file_location\n",
    "\n",
    "\n",
    "def get_xml_doc(file_location, verbose=False):\n",
    "\n",
    "    base_url = \"https://data.europarl.europa.eu/\"\n",
    "    url = base_url + file_location\n",
    "\n",
    "    if verbose:\n",
    "        print(url)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        xml_doc = ET.fromstring(response.content)\n",
    "        return xml_doc\n",
    "    else:\n",
    "        print(\"Failed to fetch data. Status code:\", response.status_code)\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_speeches_from_xml(xml_doc):\n",
    "    # Extract speaches from plenary session document\n",
    "\n",
    "    text_list = []\n",
    "    mep_ip_list = []\n",
    "    date_list = []\n",
    "    topic_list = []\n",
    "\n",
    "    date = xml_doc.find(\"HEAD\").find(\"META\").text\n",
    "    chapters = xml_doc.find(\"DEBATS\").findall(\"CHAPTER\")\n",
    "\n",
    "    for chapter in chapters:\n",
    "        # Find topic of chapter in German\n",
    "        chapter_topic = chapter.find(\"TL-CHAP[@VL='DE']\").text\n",
    "\n",
    "        interventions = chapter.findall(\"INTERVENTION\")\n",
    "        for intervention in interventions:\n",
    "            speaker = intervention.find(\"ORATEUR\")\n",
    "            # member of parlament id\n",
    "            mep_ip = speaker.attrib[\"MEPID\"]\n",
    "            # if speach in German\n",
    "            if speaker.attrib[\"LG\"] == \"DE\":\n",
    "                # find all paragraphs and concatenate to single string\n",
    "                paragraphs = intervention.findall(\"PARA\")\n",
    "                text = \"\"\n",
    "                for paragraph in paragraphs:\n",
    "                    text += \"\\n\\n\".join([text for text in paragraph.itertext()])\n",
    "\n",
    "                # Append to array\n",
    "                text_list.append(text)\n",
    "                mep_ip_list.append(mep_ip)\n",
    "                date_list.append(date)\n",
    "                topic_list.append(chapter_topic)\n",
    "\n",
    "    df_speeches = pd.DataFrame(\n",
    "        {\"date\": date, \"topic\": topic_list, \"text\": text_list, \"mep_id\": mep_ip_list}\n",
    "    )\n",
    "    return df_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fetch data. Status code: 204\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all documents of type\n",
    "type = \"PLENARY_CRE_EP\"\n",
    "type = \"CRE_PLENARY\"\n",
    "\n",
    "document_list = []\n",
    "i = 0\n",
    "while True:\n",
    "    try:\n",
    "        doc_list = get_documents(type, offset=i * 100, limit=100).json()[\"data\"]\n",
    "        if len(doc_list) == 0:\n",
    "            break\n",
    "        else:\n",
    "            document_list.extend(doc_list)\n",
    "    except:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "df_documents = pd.DataFrame(\n",
    "    {\"identifier\": [doc[\"identifier\"] for doc in document_list]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c373cae4656b4ad0878cd3a6302b7602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, id: CRE-6-2008-09-22, Error:'is_realized_by'\n",
      "Step 1, id: CRE-6-2008-09-22-FNL, Error:'is_realized_by'\n",
      "Step 658, id: CRE-8-2018-04-19-PRV, Error:'NoneType' object has no attribute 'text'\n",
      "Step 885, id: CRE-9-2019-10-23, Error:'is_realized_by'\n",
      "Step 886, id: CRE-9-2019-10-24, Error:'is_realized_by'\n",
      "Step 1004, id: CRE-9-2020-09-16, Error:'is_realized_by'\n",
      "Step 1495, id: CRE-9-2023-07-10, Error:'is_realized_by'\n",
      "Step 1514, id: CRE-9-2023-09-14, Error:'is_realized_by'\n",
      "Step 1515, id: CRE-9-2023-10-02, Error:'is_realized_by'\n",
      "Step 1516, id: CRE-9-2023-10-03, Error:'is_realized_by'\n",
      "Step 1526, id: CRE-9-2023-10-17, Error:'is_realized_by'\n",
      "Step 1529, id: CRE-9-2023-10-19, Error:'is_realized_by'\n",
      "Step 1530, id: CRE-9-2023-11-08, Error:'is_realized_by'\n",
      "Step 1531, id: CRE-9-2023-11-09, Error:'is_realized_by'\n",
      "Step 1532, id: CRE-9-2023-11-20, Error:'is_realized_by'\n",
      "Step 1533, id: CRE-9-2023-11-21, Error:'is_realized_by'\n",
      "Step 1534, id: CRE-9-2023-11-22, Error:'is_realized_by'\n",
      "Step 1535, id: CRE-9-2023-11-23, Error:'is_realized_by'\n",
      "Step 1536, id: CRE-9-2023-12-11, Error:'is_realized_by'\n",
      "Step 1537, id: CRE-9-2023-12-12, Error:'is_realized_by'\n",
      "Step 1538, id: CRE-9-2023-12-13, Error:'is_realized_by'\n",
      "Step 1539, id: CRE-9-2023-12-14, Error:'is_realized_by'\n",
      "Step 1540, id: CRE-9-2024-01-15, Error:'is_realized_by'\n",
      "Step 1541, id: CRE-9-2024-01-16, Error:'is_realized_by'\n",
      "Step 1542, id: CRE-9-2024-01-17, Error:'is_realized_by'\n",
      "Step 1543, id: CRE-9-2024-01-18, Error:'is_realized_by'\n",
      "Step 1544, id: CRE-9-2024-01-25, Error:'is_realized_by'\n",
      "Step 1545, id: CRE-9-2024-02-05, Error:'is_realized_by'\n",
      "Step 1546, id: CRE-9-2024-02-06, Error:'is_realized_by'\n",
      "Step 1549, id: CRE-9-2024-02-08, Error:'is_realized_by'\n",
      "Step 1550, id: CRE-9-2024-02-26, Error:'is_realized_by'\n",
      "Step 1551, id: CRE-9-2024-02-27, Error:'is_realized_by'\n",
      "Step 1552, id: CRE-9-2024-02-28, Error:'is_realized_by'\n",
      "Step 1553, id: CRE-9-2024-02-29, Error:'is_realized_by'\n",
      "Step 1554, id: CRE-9-2024-03-11, Error:'is_realized_by'\n",
      "Step 1555, id: CRE-9-2024-03-12, Error:'is_realized_by'\n",
      "Step 1558, id: CRE-9-2024-03-14, Error:'is_realized_by'\n",
      "Step 1559, id: CRE-9-2024-04-10, Error:'is_realized_by'\n",
      "Step 1560, id: CRE-9-2024-04-11, Error:'is_realized_by'\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "failed_documents = []\n",
    "for i, id in tqdm(enumerate(df_documents.identifier), total=len(df_documents)):\n",
    "\n",
    "    try:\n",
    "        # Get document\n",
    "        document = get_document_by_id(id).json()[\"data\"][0]\n",
    "\n",
    "        # Extract xml file location\n",
    "        file_location = get_file_location(document)\n",
    "\n",
    "        # Download xml file\n",
    "        xml_doc = get_xml_doc(file_location)\n",
    "\n",
    "        # Extract speeches from xml file\n",
    "        df_ = parse_speeches_from_xml(xml_doc)\n",
    "\n",
    "        # Append to pd.DataFrame\n",
    "        df = pd.concat([df, df_])\n",
    "    except Exception as error:\n",
    "        print(f\"Step {i}, id: {id}, Error:{error}\")\n",
    "        failed_documents.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 failed documents out of a total of 1561 !!!\n",
      "Find out what is happening!!!\n",
      "[0, 1, 658, 885, 886, 1004, 1495, 1514, 1515, 1516, 1526, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1558, 1559, 1560]\n"
     ]
    }
   ],
   "source": [
    "# TODO!!!\n",
    "print(\n",
    "    f\"{len(failed_documents)} failed documents out of a total of {len(document_list)} !!!\"\n",
    ")\n",
    "print(\"Find out what is happening!!!\")\n",
    "\n",
    "print(failed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates and reset index\n",
    "df = df.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Convert date to datetime format\n",
    "df[\"date\"] = pd.to_datetime(df.date, format=\"%d-%m-%Y\")\n",
    "\n",
    "# Change mep_ip type to int\n",
    "df[\"mep_id\"] = df[\"mep_id\"].astype(\"Int32\")\n",
    "\n",
    "# Filter 9th election period\n",
    "df = df[df[\"date\"] >= \"2019-07-02\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fullName</th>\n",
       "      <th>country</th>\n",
       "      <th>politicalGroup</th>\n",
       "      <th>nationalPoliticalGroup</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197475</th>\n",
       "      <td>Christine ANDERSON</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Identity and Democracy Group</td>\n",
       "      <td>Alternative für Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197448</th>\n",
       "      <td>Rasmus ANDRESEN</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Group of the Greens/European Free Alliance</td>\n",
       "      <td>Bündnis 90/Die Grünen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197433</th>\n",
       "      <td>Katarina BARLEY</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Group of the Progressive Alliance of Socialist...</td>\n",
       "      <td>Sozialdemokratische Partei Deutschlands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132191</th>\n",
       "      <td>Gunnar BECK</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Identity and Democracy Group</td>\n",
       "      <td>Alternative für Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197408</th>\n",
       "      <td>Hildegard BENTELE</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Group of the European People's Party (Christia...</td>\n",
       "      <td>Christlich Demokratische Union Deutschlands</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  fullName  country  \\\n",
       "id                                    \n",
       "197475  Christine ANDERSON  Germany   \n",
       "197448     Rasmus ANDRESEN  Germany   \n",
       "197433     Katarina BARLEY  Germany   \n",
       "132191         Gunnar BECK  Germany   \n",
       "197408   Hildegard BENTELE  Germany   \n",
       "\n",
       "                                           politicalGroup  \\\n",
       "id                                                          \n",
       "197475                       Identity and Democracy Group   \n",
       "197448         Group of the Greens/European Free Alliance   \n",
       "197433  Group of the Progressive Alliance of Socialist...   \n",
       "132191                       Identity and Democracy Group   \n",
       "197408  Group of the European People's Party (Christia...   \n",
       "\n",
       "                             nationalPoliticalGroup  \n",
       "id                                                   \n",
       "197475                  Alternative für Deutschland  \n",
       "197448                        Bündnis 90/Die Grünen  \n",
       "197433      Sozialdemokratische Partei Deutschlands  \n",
       "132191                  Alternative für Deutschland  \n",
       "197408  Christlich Demokratische Union Deutschlands  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xml_doc = get_mep_party()\n",
    "\n",
    "keys = [\"id\", \"fullName\", \"country\", \"politicalGroup\", \"nationalPoliticalGroup\"]\n",
    "# Create empty dictionary\n",
    "data_dict = {key: [] for key in keys}\n",
    "\n",
    "for i, mep in enumerate(xml_doc.findall(\"mep\")):\n",
    "    for j, key in enumerate(keys):\n",
    "        element = mep.find(key)\n",
    "        try:\n",
    "            data_dict[key].append(element.text)\n",
    "        except:\n",
    "            data_dict[key].append(None)\n",
    "\n",
    "df_mep_party = pd.DataFrame(data_dict)\n",
    "\n",
    "# Filter for German meps\n",
    "df_mep_party = df_mep_party[df_mep_party[\"country\"] == \"Germany\"]\n",
    "\n",
    "df_mep_party = df_mep_party.set_index(\"id\")\n",
    "df_mep_party.index = df_mep_party.index.astype(\"Int32\")\n",
    "df_mep_party = df_mep_party.drop_duplicates()\n",
    "df_mep_party.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Alternative für Deutschland', 'Bündnis 90/Die Grünen',\n",
       "       'Sozialdemokratische Partei Deutschlands',\n",
       "       'Christlich Demokratische Union Deutschlands',\n",
       "       'Bündnis Deutschland', 'Volt', 'Piratenpartei Deutschland',\n",
       "       'Independent', 'DIE LINKE.',\n",
       "       'Christlich-Soziale Union in Bayern e.V.', 'Freie Wähler',\n",
       "       'Familien-Partei Deutschlands', 'Freie Demokratische Partei',\n",
       "       'Ökologisch-Demokratische Partei', 'Die PARTEI'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mep_party.nationalPoliticalGroup.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join dataframes\n",
    "keys = df_mep_party.keys()\n",
    "\n",
    "for key in keys:\n",
    "    df[key] = df[\"mep_id\"].apply(\n",
    "        lambda x: df_mep_party.loc[x][key] if x in df_mep_party.index else None\n",
    "    )\n",
    "\n",
    "# Drop nan values (not current members of parlament)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapping for main parties\n",
    "mapping_national_parties = {\n",
    "    \"Christlich-Soziale Union in Bayern e.V.\": \"cdu\",\n",
    "    \"Christlich Demokratische Union Deutschlands\": \"cdu\",\n",
    "    \"DIE LINKE.\": \"linke\",\n",
    "    \"Alternative für Deutschland\": \"afd\",\n",
    "    \"Bündnis 90/Die Grünen\": \"gruene\",\n",
    "    \"Sozialdemokratische Partei Deutschlands\": \"spd\",\n",
    "    \"Freie Demokratische Partei\": \"fdp\",\n",
    "    \"Volt\": \"volt\",\n",
    "    \"Freie Wähler\": \"fw\",\n",
    "    \"Familien-Partei Deutschlands\": \"familie\",\n",
    "    \"Ökologisch-Demokratische Partei\": \"oedp\",\n",
    "    \"Piratenpartei Deutschland\": \"piraten\",\n",
    "}\n",
    "\n",
    "# Map other parties to \"other\"\n",
    "for party in df[\"nationalPoliticalGroup\"].unique():\n",
    "    if not party in mapping_national_parties.keys():\n",
    "        mapping_national_parties.update({party: \"other\"})\n",
    "\n",
    "# Map names\n",
    "df[\"party\"] = df[\"nationalPoliticalGroup\"].apply(lambda x: mapping_national_parties[x])\n",
    "# Drop old column\n",
    "df = df.drop(columns=[\"nationalPoliticalGroup\"])\n",
    "\n",
    "# Drop \"other\" parties\n",
    "df = df[df[\"party\"] != \"other\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save file\n",
    "df.to_csv(\"../data/debates/europarl_speeches.csv\")\n",
    "df_mep_party.to_csv(\"../data/debates/europarl_members.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bundestag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
