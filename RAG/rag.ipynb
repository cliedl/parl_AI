{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval-augmented generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build vector store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Manifestoberta Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manifestoberta needs to be wrapped into an Embedding class compatible with LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Joshua/opt/anaconda3/envs/politik-nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of XLMRobertaModel were not initialized from the model checkpoint at manifesto-project/manifestoberta-xlm-roberta-56policy-topics-sentence-2023-1-1 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from langchain_core.embeddings import Embeddings\n",
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class ManifestoBertaEmbeddings(Embeddings):\n",
    "    \"\"\"Embeddings using ManifestoBerta for use with LangChain.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Load the tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            \"manifesto-project/manifestoberta-xlm-roberta-56policy-topics-sentence-2023-1-1\"\n",
    "        )\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            \"manifesto-project/manifestoberta-xlm-roberta-56policy-topics-sentence-2023-1-1\"\n",
    "        )\n",
    "\n",
    "    def _embed(self, text: str, sentence_level=True) -> List[float]:\n",
    "        \"\"\"Embed a text using ManifestoBerta.\n",
    "\n",
    "        Args:\n",
    "            text: The text to embed.\n",
    "\n",
    "        Returns:\n",
    "            Embeddings for the text.\n",
    "        \"\"\"\n",
    "\n",
    "        # Encode the text\n",
    "        inputs = self.tokenizer(\n",
    "            text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512\n",
    "        )\n",
    "\n",
    "        # Get model output (make sure to set output_hidden_states to True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs, output_hidden_states=True)\n",
    "\n",
    "        # Extract the last hidden states\n",
    "        last_hidden_states = outputs.hidden_states[-1]\n",
    "\n",
    "        # Optionally, you can average the token embeddings for sentence-level representation\n",
    "        if sentence_level:\n",
    "            embedding = torch.mean(last_hidden_states, dim=1)\n",
    "        else:\n",
    "            embedding = last_hidden_states\n",
    "\n",
    "        # Convert to list\n",
    "        embedding_list = embedding.cpu().tolist()\n",
    "\n",
    "        return embedding_list[0]\n",
    "\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return [self._embed(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        # return self.embed_documents([text])[0] # previous version\n",
    "        return self._embed(text)\n",
    "    \n",
    "embeddings = ManifestoBertaEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create or load vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "import os\n",
    "\n",
    "# Build vector storage if not yet existing\n",
    "if not os.path.exists(\"./chroma\"):\n",
    "\n",
    "    loader = PyPDFDirectoryLoader(\n",
    "        \"../data/manifestos/01_pdf_originals/\"\n",
    "    )  # file name and page number are stored as metadata when loading from directory\n",
    "    \n",
    "    # loader = PyPDFDirectoryLoader(\"./dummy_pdf\") # alternative for quick testing\n",
    "\n",
    "    docs = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "\n",
    "    db = Chroma.from_documents(splits, embeddings, persist_directory=\"./chroma\")\n",
    "\n",
    "# Load the vector storage if it already exists\n",
    "else:\n",
    "    db = Chroma(persist_directory=\"./chroma\", embedding_function=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval and generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO: Develop solution to retrieve from multiple parties in a balanced way (e.g., using multiple retrievers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\",\n",
    "                 max_tokens=1000,\n",
    "                 temperature=0.7)\n",
    "\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\": 10,\n",
    "        # \"where\": {  # https://docs.trychroma.com/usage-guide#using-where-filters\n",
    "        #     \"source\": \"\" # TODO: add an exact file name here for testing purposes\n",
    "        # },\n",
    "    },\n",
    ")\n",
    "\n",
    "question_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Du hilfst dabei, die politischen Positionen verschiedener Parteien zur Europawahl 2024 zusammenzufassen und zu vergleichen.\n",
    "Beantworte die folgende Frage nur auf dem zur Verfügung gestellten Kontext.\n",
    "Falls sich die Frage auf Basis des Kontexts nicht beantworten lässt, gib eine kurze Begründung an.\n",
    "                                          \n",
    "KONTEXT:\n",
    "{context}\n",
    "\n",
    "FRAGE: {question}\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | question_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"Welche Ansätze zur Bewältigung der Klimakrise werden von den verschiedenen Parteien vorgeschlagen?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slightly better chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Die Linke setzt auf eine konsequente Energiewende und erneuerbare Energien, kritisiert jedoch konservative und liberale Parteien für ihre angebliche Verlangsamung der Energiewende zugunsten fossiler Energieträger. Die AfD hingegen zweifelt den menschengemachten Klimawandel an und setzt auf Anpassungsstrategien an vermeintliche natürliche Klimaveränderungen. Sie lehnt den Ausbau von Windkraftanlagen ab und betont den Erhalt von fossilen Energieträgern. Die Grünen hingegen setzen auf Naturschutzmaßnahmen zur Bewältigung der Klimakrise, wie die Renaturierung von Gewässern und den Ausbau erneuerbarer Energien.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain_core.prompts import PromptTemplate, format_document\n",
    "\n",
    "def _combine_documents(docs, document_separator=\"\\n\\n\"):\n",
    "    document_prompt = PromptTemplate.from_template(\n",
    "        template=\"Ausschnitt aus dem Europawahlprogramm 2024 '{source}': \\n {page_content}\"\n",
    "    )\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)\n",
    "\n",
    "_inputs = RunnableParallel(\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": RunnablePassthrough() | retriever | _combine_documents,\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = _inputs | question_prompt | llm | StrOutputParser()\n",
    "\n",
    "chain.invoke(\n",
    "    \"Welche Ansätze zur Bewältigung der Klimakrise werden von den verschiedenen Parteien vorgeschlagen?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "politik-nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
